{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c89fe9e",
   "metadata": {},
   "source": [
    "This is an EDA for Benin solar energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cce4b",
   "metadata": {},
   "source": [
    "# Step one\n",
    "# Lets import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3265ecb",
   "metadata": {},
   "source": [
    "# Step Two\n",
    "# Loading the data of the solar energy. It is a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/benin.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d410dfc",
   "metadata": {},
   "source": [
    "# Lets see the first and last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53800c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lets see a random 5 rows among all entries\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"information about the dataset\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adf8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"check missing values\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e47e55",
   "metadata": {},
   "source": [
    "# Now lets do a descriptive statistics for numerical columns. Bear in mind that categorical columns are ignored automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12973c6",
   "metadata": {},
   "source": [
    "# Now lets do a descriptive statistics for the categorical column only. That can be done by simply setting the include parameter 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90558782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99193a07",
   "metadata": {},
   "source": [
    "# Now lets do a descriptive statistics for both numerical and categorical columns. We just have to set the include parameter 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898c02b",
   "metadata": {},
   "source": [
    "# as we can see from the above result, uniqe, top, freq are the only parameters that belongs to the categorical column. The only categorical colulmn is timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets go for duplicate rows\n",
    "# duplicated().sum() is used to identify and sum duplicated rows for both numerical and categorical columns\n",
    "number_of_duplicates = df.duplicated().sum()\n",
    "print(f\"duplicated entries are: {number_of_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876f739",
   "metadata": {},
   "source": [
    "# Lets see cardinallity (uniqueness) of categoricalls. Low cardinality → easy to summarize and analyze, Medium cardinality -> Some ML encodings (one-hot may become large; label encoding or embeddings preferred). High cardinality -> Hard to summarize descriptively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cardinality = {crd:df[crd].nunique() for crd in categorical_column}\n",
    "print (cardinality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91d972",
   "metadata": {},
   "source": [
    "# lets consider cardinality of both categoricals and numercal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7452818",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = df.select_dtypes(include=[\"object\", \"category\", \"float64\", \"int64\"]).columns.tolist()\n",
    "cardinality = {crd:df[crd].nunique() for crd in categorical_column}\n",
    "print (cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying columns with missing values greater than 5 percent\n",
    "missing_percent = df.isnull().mean()*100\n",
    "missing_greater_than_five_percent = missing_percent[missing_percent>5]\n",
    "print(missing_greater_than_five_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c71097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for invalid data types\n",
    "# For example, a numeric column should only contain numbers.\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    invalid = df[~df[col].apply(lambda x: isinstance(x, (int, float)))]\n",
    "    if not invalid.empty:\n",
    "        print(f\"Invalid entries in {col}:\")\n",
    "        print(invalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1205f",
   "metadata": {},
   "source": [
    "# Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    plt.figure()\n",
    "    sns.histplot(df[c],kde=True)\n",
    "    plt.title(f\"Distribution of {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d97c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df[c].dropna(), vert =True)\n",
    "    plt.title(f\"box plot of {c}\")\n",
    "    plt.ylabel(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3bb557",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before calculating Z score, first we have to remove columns that have NaN values\n",
    "\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score method. it is know that this method is only for numerical columns. \n",
    "# the most common threshold value of z is 3. if z is above 3, so , that particular cell value is an outlier\n",
    "\n",
    "num_cols = df.select_dtypes(include= [np.number]).columns.tolist() # num_cols is a list of numeric column names\n",
    "z_scores = np.abs(stats.zscore(df[num_cols]))\n",
    "threshold = 3\n",
    "outliers = (z_scores>threshold)\n",
    "outler_counts = pd.DataFrame(outliers, columns=num_cols).sum()\n",
    "print(outler_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets keep rows whose z score value is less than or equal to 3\n",
    "\n",
    "df_clean = df[(z_scores<=3).all(axis=1)]\n",
    "# size of the  cleaned data\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets export the cleaned data\n",
    "df_clean.to_csv(\"../data/cleaned_data_benin.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1d156",
   "metadata": {},
   "source": [
    "# Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e28d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line charts of GHI, DNI, DHI, Tamb Vs Timestamp\n",
    "# I have to ensure if the timestamp column is in a standard date time format\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "columns_to_plot = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
    "plt.Figure(figsize=(15,6))\n",
    "for col in columns_to_plot:\n",
    "    plt.plot(df['Timestamp'], df[col], label = col)\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('values')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets observe patterns by month, we need to extract the month from Timestamp column and then aggregate the data by mean per month.\n",
    "df['Month'] = df['Timestamp'].dt.month  # .dt.month extracts the month as an integer (1 for January, 2 for February).\n",
    "monthly_avg = df.groupby('Month')[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "plt.figure(figsize=(12,6))\n",
    "for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "    plt.plot(monthly_avg.index, monthly_avg[col], marker='o', label=col)\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Monthly Pattern of Solar and Temperature Variables')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d26bc",
   "metadata": {},
   "source": [
    "# Cleaning Impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed47293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Cleaning column and compute mean of ModA and ModB\n",
    "cleaning_impact = df.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
    "print(cleaning_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bd022",
   "metadata": {},
   "source": [
    "# Correlation & Relationship Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: WS, WSgust, WD vs. GHI; RH vs. Tamb or RH vs. GHI.\n",
    "\n",
    "for col in ['WS', 'WSgust', 'WD']:\n",
    "    plt.Figure(figsize=(6,4))\n",
    "    plt.scatter(df[col], df['GHI'], alpha=0.5)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('GHI')\n",
    "    plt.title(f'{col} vs GHI')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Tamb', 'GHI']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(df['RH'], df[col], alpha=0.5)\n",
    "    plt.xlabel('RH')\n",
    "    plt.ylabel(col)\n",
    "    plt.title(f'RH vs {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of correlations (GHI, DNI, DHI, TModA, TModB).\n",
    "cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df[cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66007986",
   "metadata": {},
   "source": [
    "# Wind & Distribution Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind rose or radial bar plot of WS/WD.\n",
    "from windrose import WindroseAxes\n",
    "ax = WindroseAxes.from_ax()\n",
    "ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "ax.set_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram + density for GHI\n",
    "sns.histplot(df['GHI'], kde=True, bins=30, color='skyblue')\n",
    "plt.title('Histogram & Density of GHI')\n",
    "plt.show()\n",
    "\n",
    "# Histogram + density for WS\n",
    "sns.histplot(df['WS'], kde=True, bins=30, color='salmon')\n",
    "plt.title('Histogram & Density of WS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caba854",
   "metadata": {},
   "source": [
    "# Temperature Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how relative humidity (RH) might influence temperature readings and solar radiation.\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x='RH', y='Tamb', data=df)\n",
    "plt.title('Relative Humidity vs Ambient Temperature')\n",
    "plt.xlabel('Relative Humidity (%)')\n",
    "plt.ylabel('Ambient Temperature (°C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7939b",
   "metadata": {},
   "source": [
    "# Bubble Chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHI vs. Tamb with bubble size = RH or BP.\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Bubble chart\n",
    "plt.scatter(\n",
    "    x=df['GHI'], \n",
    "    y=df['Tamb'], \n",
    "    s=df['RH'],           # Bubble size\n",
    "    alpha=0.5,            # Transparency\n",
    "    c='gray',             # Bubble color\n",
    "    edgecolor='k'         # Bubble edge color\n",
    ")\n",
    "\n",
    "plt.title('GHI vs Ambient Temperature with Bubble Size = RH')\n",
    "plt.xlabel('GHI (W/m²)')\n",
    "plt.ylabel('Tamb (°C)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52ca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
